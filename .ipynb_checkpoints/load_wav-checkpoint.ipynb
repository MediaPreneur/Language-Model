{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import os\n",
    "import librosa as lr\n",
    "import shutil\n",
    "\n",
    "from skimage.io import imread\n",
    "import h5py\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "from keras.optimizers import Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dim = (192,192,1)\n",
    "out_dim = 176\n",
    "batch_size = 32\n",
    "wav_path = 'data/roller/'\n",
    "tr_path = 'data/train_wav/'\n",
    "va_path = 'data/valid_wav/'\n",
    "te_path = 'data/test_wav/'\n",
    "data_size = 66176\n",
    "tr_size = 52800\n",
    "va_size = 4576\n",
    "te_size = 8800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def process_audio(in_folder, out_folder, sub_folder):\n",
    "    \n",
    "    os.makedirs(os.path.join(out_folder, 'train_wav/' + sub_folder), exist_ok=True)\n",
    "    os.makedirs(os.path.join(out_folder, 'valid_wav/' + sub_folder), exist_ok=True)\n",
    "    os.makedirs(os.path.join(out_folder, 'test_wav/unknown'), exist_ok=True)\n",
    "    files = shuffle(glob.glob(in_folder+'*.wav'))\n",
    "    numb_files = len(files)\n",
    "    num_train =int( 0.6*numb_files)\n",
    "    num_test = int(0.2*numb_files)\n",
    "    num_valid = int(0.2*numb_files)\n",
    "    train, test, valid = files[:num_train],files[num_train:num_train+num_test], files[num_train+num_test:]\n",
    "    start = len(in_folder)\n",
    "    for file in train:\n",
    "        img = wav_to_img(file)\n",
    "        sp.misc.imsave(os.path.join(out_folder, 'train_wav/' + sub_folder + \"/\") + file[start:] + '.jpg', img)\n",
    "    for file in test:\n",
    "        img = wav_to_img(file)\n",
    "        sp.misc.imsave(os.path.join(out_folder, 'test_wav/unknown/') + file[start:] + '.jpg', img)\n",
    "        \n",
    "    for file in valid:\n",
    "        img = wav_to_img(file)\n",
    "        sp.misc.imsave(os.path.join(out_folder, 'valid_wav/', sub_folder+'/') + file[start:] + '.jpg', img)\n",
    "        \n",
    "def process_audio_with_classes(in_folder, out_folder, labels):\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "    for i in range(len(labels['Sample Filename'])):\n",
    "        file = labels['Sample Filename'][i]\n",
    "        lang = labels['Language'][i]\n",
    "        os.makedirs(out_folder + lang, exist_ok=True)\n",
    "        img = mp3_to_img(in_folder+file)\n",
    "        sp.misc.imsave(out_folder + lang + '/' + file + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_audio('data/roller/fast/', 'data', 'fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_audio('data/roller/slow/', 'data', 'slow'),\n",
    "process_audio('data/roller/very_fast/', 'data', 'very_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import os\n",
    "def load_dataset(base_dir):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    files = glob.glob(base_dir + '/fast/*.jpg')\n",
    "    yy=[1,0,0]\n",
    "    for file in files:\n",
    "        x += [np.reshape(scipy.ndimage.imread(file),in_dim )]\n",
    "        y += [yy]\n",
    "    yy = [0,1,0]\n",
    "    files = glob.glob(base_dir + '/slow/*.jpg')\n",
    "    for file in files:\n",
    "        x += [np.reshape(scipy.ndimage.imread(file),in_dim )]\n",
    "        y += [yy]\n",
    "    yy = [0,0,1]\n",
    "    files = glob.glob(base_dir + '/very_fast/*.jpg')\n",
    "    for file in files:\n",
    "        x += [np.reshape(scipy.ndimage.imread(file),in_dim )]\n",
    "        y += [yy]\n",
    "\n",
    "    x,y = shuffle(x,y)\n",
    "    x = np.array(x)/255.0\n",
    "    y = np.array(y)\n",
    "    return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 192, 192, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 192, 192, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 96, 96, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 96, 96, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               4719104   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 176)               90288     \n",
      "=================================================================\n",
      "Total params: 5,201,712\n",
      "Trainable params: 5,201,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "i = Input(shape=in_dim)\n",
    "m = Conv2D(16, (3, 3), activation='elu', padding='same')(i)\n",
    "m = MaxPooling2D()(m)\n",
    "m = Conv2D(32, (3, 3), activation='elu', padding='same')(m)\n",
    "m = MaxPooling2D()(m)\n",
    "m = Conv2D(64, (3, 3), activation='elu', padding='same')(m)\n",
    "m = MaxPooling2D()(m)\n",
    "m = Conv2D(128, (3, 3), activation='elu', padding='same')(m)\n",
    "m = MaxPooling2D()(m)\n",
    "m = Conv2D(256, (3, 3), activation='elu', padding='same')(m)\n",
    "m = MaxPooling2D()(m)\n",
    "hidden = Flatten()(m)\n",
    "hidden_1 = Dense(512, activation='elu')(hidden)\n",
    "m = Dropout(0.5)(hidden_1)\n",
    "o = Dense(out_dim, activation='softmax')(m)\n",
    "\n",
    "model = Model(inputs=i, outputs=o)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Nadam(lr=1e-3), metrics=['accuracy'])\n",
    "model = load_model('speech_v9.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 3) (135, 3)\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(inputs=i, outputs=hidden)\n",
    "x, y_tr = load_dataset(\"data/train_wav\")\n",
    "\n",
    "x_tr =model2.predict(x)\n",
    "N, D = x_tr.shape\n",
    "\n",
    "x, y_val = load_dataset('data/valid_wav')\n",
    "x_val = model2.predict(x)\n",
    "\n",
    "print (y_tr.shape, y_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9216\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 512)               4719104   \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 4,822,307\n",
      "Trainable params: 4,822,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "print(D)\n",
    "i1 =  Input(shape=[D])\n",
    "m1 = Dense(512, activation='elu')(i1)\n",
    "m1 = Dropout(0.5)(m1)\n",
    "m1 = Dense(200)(m1)\n",
    "m1 = Dropout(0.2)(m1)\n",
    "o1 = Dense(M, activation='softmax')(m1)\n",
    "model_audio = Model(inputs=i1, outputs=o1)\n",
    "model_audio.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 3) (135, 3)\n"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "optmiser = K.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model_audio.compile(loss='categorical_crossentropy', optimizer=optmiser, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "print(y_tr.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_audio_wait = 'model_adio.weights.best.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 393 samples, validate on 135 samples\n",
      "Epoch 1/20\n",
      "Epoch 00000: val_loss improved from inf to 0.69417, saving model to model_adio.weights.best.hdf5\n",
      "1s - loss: 0.6102 - acc: 0.7455 - val_loss: 0.6942 - val_acc: 0.7111\n",
      "Epoch 2/20\n",
      "Epoch 00001: val_loss improved from 0.69417 to 0.67934, saving model to model_adio.weights.best.hdf5\n",
      "0s - loss: 0.6071 - acc: 0.7532 - val_loss: 0.6793 - val_acc: 0.6593\n",
      "Epoch 3/20\n",
      "Epoch 00002: val_loss improved from 0.67934 to 0.67296, saving model to model_adio.weights.best.hdf5\n",
      "0s - loss: 0.5970 - acc: 0.7532 - val_loss: 0.6730 - val_acc: 0.6667\n",
      "Epoch 4/20\n",
      "Epoch 00003: val_loss did not improve\n",
      "0s - loss: 0.6066 - acc: 0.7277 - val_loss: 0.6864 - val_acc: 0.6889\n",
      "Epoch 5/20\n",
      "Epoch 00004: val_loss improved from 0.67296 to 0.67007, saving model to model_adio.weights.best.hdf5\n",
      "0s - loss: 0.6095 - acc: 0.7481 - val_loss: 0.6701 - val_acc: 0.6667\n",
      "Epoch 6/20\n",
      "Epoch 00005: val_loss did not improve\n",
      "0s - loss: 0.5934 - acc: 0.7405 - val_loss: 0.6703 - val_acc: 0.6593\n",
      "Epoch 7/20\n",
      "Epoch 00006: val_loss did not improve\n",
      "0s - loss: 0.5844 - acc: 0.7939 - val_loss: 0.6726 - val_acc: 0.6519\n",
      "Epoch 8/20\n",
      "Epoch 00007: val_loss did not improve\n",
      "0s - loss: 0.5760 - acc: 0.7837 - val_loss: 0.6757 - val_acc: 0.6519\n",
      "Epoch 9/20\n",
      "Epoch 00008: val_loss improved from 0.67007 to 0.66426, saving model to model_adio.weights.best.hdf5\n",
      "0s - loss: 0.6138 - acc: 0.7379 - val_loss: 0.6643 - val_acc: 0.6667\n",
      "Epoch 10/20\n",
      "Epoch 00009: val_loss did not improve\n",
      "0s - loss: 0.5932 - acc: 0.7710 - val_loss: 0.6725 - val_acc: 0.6815\n",
      "Epoch 11/20\n",
      "Epoch 00010: val_loss did not improve\n",
      "0s - loss: 0.5675 - acc: 0.7735 - val_loss: 0.6649 - val_acc: 0.6815\n",
      "Epoch 12/20\n",
      "Epoch 00011: val_loss improved from 0.66426 to 0.66128, saving model to model_adio.weights.best.hdf5\n",
      "0s - loss: 0.5668 - acc: 0.7913 - val_loss: 0.6613 - val_acc: 0.6667\n",
      "Epoch 13/20\n",
      "Epoch 00012: val_loss improved from 0.66128 to 0.66000, saving model to model_adio.weights.best.hdf5\n",
      "0s - loss: 0.5691 - acc: 0.7583 - val_loss: 0.6600 - val_acc: 0.6593\n",
      "Epoch 14/20\n",
      "Epoch 00013: val_loss did not improve\n",
      "0s - loss: 0.5557 - acc: 0.7939 - val_loss: 0.6610 - val_acc: 0.6667\n",
      "Epoch 15/20\n",
      "Epoch 00014: val_loss improved from 0.66000 to 0.65754, saving model to model_adio.weights.best.hdf5\n",
      "0s - loss: 0.5695 - acc: 0.7761 - val_loss: 0.6575 - val_acc: 0.6667\n",
      "Epoch 16/20\n",
      "Epoch 00015: val_loss did not improve\n",
      "0s - loss: 0.5529 - acc: 0.7913 - val_loss: 0.6583 - val_acc: 0.6593\n",
      "Epoch 17/20\n",
      "Epoch 00016: val_loss improved from 0.65754 to 0.65668, saving model to model_adio.weights.best.hdf5\n",
      "0s - loss: 0.5528 - acc: 0.7710 - val_loss: 0.6567 - val_acc: 0.6667\n",
      "Epoch 18/20\n",
      "Epoch 00017: val_loss did not improve\n",
      "0s - loss: 0.5517 - acc: 0.7659 - val_loss: 0.6639 - val_acc: 0.6815\n",
      "Epoch 19/20\n",
      "Epoch 00018: val_loss did not improve\n",
      "0s - loss: 0.5327 - acc: 0.7990 - val_loss: 0.6620 - val_acc: 0.6741\n",
      "Epoch 20/20\n",
      "Epoch 00019: val_loss did not improve\n",
      "0s - loss: 0.5456 - acc: 0.8041 - val_loss: 0.6584 - val_acc: 0.6593\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "model_audio = load_model(model_audio_wait)\n",
    "checkpointer = ModelCheckpoint(filepath=model_audio_wait, verbose=1, \n",
    "                               save_best_only=True)\n",
    "hist = model_audio.fit(x_tr, y_tr, batch_size=100, epochs=20,\n",
    "          validation_data=(x_val, y_val), callbacks=[checkpointer], \n",
    "          verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
